{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ff6b4-429f-4064-ba55-a501a9b563d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import zscore\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "import json\n",
    "\n",
    "class AdvancedFinancialAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained financial sentiment model\n",
    "        self.sentiment_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "        \n",
    "        # Advanced feature extraction patterns\n",
    "        self.advanced_patterns = {\n",
    "            'risk_indicators': [\n",
    "                r'(?:high\\s*risk|significant\\s*risk|potential\\s*liability)',\n",
    "                r'(?:market\\s*volatility|economic\\s*uncertainty)',\n",
    "                r'(?:regulatory\\s*challenge|compliance\\s*issue)'\n",
    "            ],\n",
    "            'growth_signals': [\n",
    "                r'(?:strategic\\s*expansion|market\\s*opportunity|innovation)',\n",
    "                r'(?:new\\s*market\\s*entry|product\\s*development)',\n",
    "                r'(?:merger\\s*acquisition|strategic\\s*partnership)'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def extract_advanced_insights(self, text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Advanced text analysis with multiple insight extraction techniques\n",
    "        \"\"\"\n",
    "        insights = {\n",
    "            'risk_indicators': [],\n",
    "            'growth_signals': [],\n",
    "            'sentiment_score': self.analyze_financial_sentiment(text)\n",
    "        }\n",
    "        \n",
    "        # Extract advanced patterns\n",
    "        for category, patterns in self.advanced_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                insights[category].extend(matches)\n",
    "        \n",
    "        return insights\n",
    "\n",
    "    def analyze_financial_sentiment(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Advanced financial sentiment analysis using FinBERT\n",
    "        \"\"\"\n",
    "        try:\n",
    "            inputs = self.sentiment_tokenizer(text, return_tensors=\"pt\", \n",
    "                                              truncation=True, \n",
    "                                              max_length=512)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.sentiment_model(**inputs)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "            sentiment_scores = {\n",
    "                'negative': probabilities[0][0].item(),\n",
    "                'neutral': probabilities[0][1].item(),\n",
    "                'positive': probabilities[0][2].item()\n",
    "            }\n",
    "            \n",
    "            # Normalized sentiment score\n",
    "            return (sentiment_scores['positive'] - sentiment_scores['negative']) * 100\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Sentiment analysis error: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def detect_financial_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Machine learning-based anomaly detection\n",
    "        \"\"\"\n",
    "        # Select numeric columns for anomaly detection\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[numeric_columns]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Isolation Forest for anomaly detection\n",
    "        clf = IsolationForest(contamination=0.1, random_state=42)\n",
    "        y_pred = clf.fit_predict(X_scaled)\n",
    "        \n",
    "        # Add anomaly flag to dataframe\n",
    "        df['is_anomaly'] = y_pred\n",
    "        df['anomaly_score'] = clf.decision_function(X_scaled)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def document_similarity_analysis(self, documents: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Advanced document similarity comparison\n",
    "        \"\"\"\n",
    "        # TF-IDF Vectorization\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "        \n",
    "        # Cosine similarity matrix\n",
    "        similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        return similarity_matrix\n",
    "\n",
    "    def predictive_financial_modeling(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Simple predictive modeling for financial metrics\n",
    "        \"\"\"\n",
    "        # Prepare features and target\n",
    "        features = ['revenue', 'net_income', 'eps']\n",
    "        \n",
    "        # Check if we have enough data for prediction\n",
    "        if len(df) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Simple linear extrapolation\n",
    "        predictions = {}\n",
    "        for feature in features:\n",
    "            if feature in df.columns:\n",
    "                # Linear regression-like extrapolation\n",
    "                lr_model = np.polyfit(range(len(df)), df[feature], 1)\n",
    "                future_prediction = np.poly1d(lr_model)(len(df))\n",
    "                predictions[feature] = future_prediction\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "def main():\n",
    "    st.title(\"Advanced Financial Intelligence System\")\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = AdvancedFinancialAnalyzer()\n",
    "    \n",
    "    # File upload with multiple file support\n",
    "    uploaded_files = st.file_uploader(\n",
    "        \"Upload Financial Reports (PDFs)\", \n",
    "        type=\"pdf\", \n",
    "        accept_multiple_files=True\n",
    "    )\n",
    "    \n",
    "    if uploaded_files:\n",
    "        # Containers for different analysis sections\n",
    "        insights_container = st.container()\n",
    "        anomaly_container = st.container()\n",
    "        similarity_container = st.container()\n",
    "        predictive_container = st.container()\n",
    "        \n",
    "        # Collect and process documents\n",
    "        all_documents = []\n",
    "        document_texts = []\n",
    "        \n",
    "        for uploaded_file in uploaded_files:\n",
    "            # PDF Processing (you'd replace this with your existing PDF processing logic)\n",
    "            with open(\"temp.pdf\", \"wb\") as f:\n",
    "                f.write(uploaded_file.getvalue())\n",
    "            \n",
    "            # Extract text (simplified for this example)\n",
    "            with open(\"temp.pdf\", \"rb\") as f:\n",
    "                text = f.read().decode('utf-8', errors='ignore')\n",
    "            \n",
    "            document_texts.append(text)\n",
    "            \n",
    "            # Advanced insights extraction\n",
    "            advanced_insights = analyzer.extract_advanced_insights(text)\n",
    "            \n",
    "            with insights_container:\n",
    "                st.subheader(\"Advanced Textual Insights\")\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                \n",
    "                with col1:\n",
    "                    st.metric(\"Sentiment Score\", \n",
    "                              f\"{advanced_insights['sentiment_score']:.2f}\", \n",
    "                              delta_color=\"inverse\")\n",
    "                \n",
    "                with col2:\n",
    "                    st.write(\"Risk Indicators:\")\n",
    "                    st.json(advanced_insights['risk_indicators'])\n",
    "                \n",
    "                with col3:\n",
    "                    st.write(\"Growth Signals:\")\n",
    "                    st.json(advanced_insights['growth_signals'])\n",
    "        \n",
    "        # Anomaly Detection\n",
    "        # (Assuming you have a DataFrame from previous processing)\n",
    "        df = pd.DataFrame({\n",
    "            'revenue': [100, 120, 110, 130, 140],\n",
    "            'net_income': [20, 25, 22, 30, 35],\n",
    "            'eps': [0.5, 0.6, 0.55, 0.7, 0.8]\n",
    "        })\n",
    "        \n",
    "        anomaly_df = analyzer.detect_financial_anomalies(df)\n",
    "        \n",
    "        with anomaly_container:\n",
    "            st.subheader(\"Anomaly Detection\")\n",
    "            \n",
    "            # Visualize anomalies\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=anomaly_df.index, \n",
    "                y=anomaly_df['revenue'], \n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=anomaly_df['is_anomaly'].map({1: 'blue', -1: 'red'}),\n",
    "                    size=10\n",
    "                ),\n",
    "                name='Revenue'\n",
    "            ))\n",
    "            \n",
    "            st.plotly_chart(fig)\n",
    "            \n",
    "            # Anomaly details\n",
    "            st.dataframe(anomaly_df[anomaly_df['is_anomaly'] == -1])\n",
    "        \n",
    "        # Document Similarity\n",
    "        similarity_matrix = analyzer.document_similarity_analysis(document_texts)\n",
    "        \n",
    "        with similarity_container:\n",
    "            st.subheader(\"Document Similarity Analysis\")\n",
    "            \n",
    "            # Heatmap of document similarities\n",
    "            fig = px.imshow(\n",
    "                similarity_matrix, \n",
    "                labels=dict(x=\"Document\", y=\"Document\", color=\"Similarity\"),\n",
    "                title=\"Document Similarity Heatmap\"\n",
    "            )\n",
    "            st.plotly_chart(fig)\n",
    "        \n",
    "        # Predictive Modeling\n",
    "        predictions = analyzer.predictive_financial_modeling(df)\n",
    "        \n",
    "        with predictive_container:\n",
    "            st.subheader(\"Predictive Financial Modeling\")\n",
    "            \n",
    "            if predictions:\n",
    "                # Visualize predictions\n",
    "                fig = go.Figure()\n",
    "                for metric, prediction in predictions.items():\n",
    "                    fig.add_trace(go.Scatter(\n",
    "                        x=list(df.index) + [len(df)],\n",
    "                        y=list(df[metric]) + [prediction],\n",
    "                        mode='lines+markers',\n",
    "                        name=f'{metric} Prediction'\n",
    "                    ))\n",
    "                \n",
    "                st.plotly_chart(fig)\n",
    "                \n",
    "                # Display predictions\n",
    "                st.json(predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
